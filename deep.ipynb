{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\",train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\",train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 5, 7, 4, 7, 1, 5, 6, 7, 6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "x , y = data[0][0] ,data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0 }\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)]  +=1\n",
    "        total +=1\n",
    "        \n",
    "print(counter_dict)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:9.871666666666666\n",
      "1:11.236666666666666\n",
      "2:9.93\n",
      "3:10.218333333333334\n",
      "4:9.736666666666666\n",
      "5:9.035\n",
      "6:9.863333333333333\n",
      "7:10.441666666666666\n",
      "8:9.751666666666667\n",
      "9:9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}:{counter_dict[i]/total*100}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(1,28*28)\n",
    "output = net(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2313, -2.3019, -2.3626, -2.3821, -2.3248, -2.3636, -2.2765, -2.2608,\n",
       "         -2.1866, -2.3547]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1441, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    " \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.968\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X.view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0562e+01, -1.2288e+01, -1.4524e+01, -1.4406e+01, -1.6325e+01,\n",
      "        -9.5218e+00, -7.7459e+00, -1.5509e+01, -5.3856e-04, -1.4156e+01],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0562e+01, -1.2288e+01, -1.4524e+01, -1.4406e+01, -1.6325e+01,\n",
       "         -9.5218e+00, -7.7459e+00, -1.5509e+01, -5.3856e-04, -1.4156e+01]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_featureset = X[0]\n",
    "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
    "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
    "first_pred = output[0]\n",
    "print(first_pred)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "biggest_index = torch.argmax(output)\n",
    "print(biggest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
